#!/usr/bin/env python3

import json
import os
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from sentence_transformers import SentenceTransformer
import openai
from sklearn.metrics.pairwise import cosine_similarity
import re
import logging
from datetime import datetime

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class RetrievedPost:
    content: str
    similarity: float
    post_type: str
    keywords: List[str]

class AromaKissRAG:
    def __init__(self, openai_api_key: str, messages_file: str = "messages_simple_list.json"):
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        self.messages_file = messages_file
        
        logger.info("Loading multilingual sentence transformer...")
        self.encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        self.posts = []
        self.embeddings = None
        self.post_metadata = []
        
        self._load_and_process_messages()
        self._create_embeddings()
        
        logger.info(f"RAG system initialized with {len(self.posts)} posts")
    
    def _load_and_process_messages(self):
        try:
            with open(self.messages_file, 'r', encoding='utf-8') as f:
                self.posts = json.load(f)
            
            for i, post in enumerate(self.posts):
                metadata = self._analyze_post(post)
                self.post_metadata.append(metadata)
                
        except FileNotFoundError:
            logger.error(f"Messages file {self.messages_file} not found")
            raise
        except json.JSONDecodeError:
            logger.error(f"Invalid JSON in {self.messages_file}")
            raise
    
    def _analyze_post(self, post: str) -> Dict:
        metadata = {
            'length': len(post),
            'has_emoji': bool(re.search(r'[üòÄ-üôèüåÄ-üóøüöÄ-üõø]', post)),
            'has_hashtag': '#' in post,
            'post_type': 'general',
            'topics': [],
            'season': None,
            'sentiment': 'neutral'
        }
        
        post_lower = post.lower()
        
        if any(word in post_lower for word in ['–∏–Ω—Ç–µ—Ä–µ—Å–Ω', '—Ñ–∞–∫—Ç']):
            metadata['post_type'] = 'educational'
        elif any(word in post_lower for word in ['–Ω–æ–≤–æ–≥–æ–¥', '—Ä–æ–∂–¥–µ—Å—Ç–≤', '8 –º–∞—Ä—Ç–∞', '–≤–µ—Å–Ω']):
            metadata['post_type'] = 'seasonal'
        elif any(word in post_lower for word in ['–∞—Ä–æ–º–∞—Ç', '–∑–∞–ø–∞—Ö', '–ø–∞—Ä—Ñ—é–º']):
            metadata['post_type'] = 'fragrance'
        elif any(word in post_lower for word in ['–¥–µ–∫–æ—Ä', '—Å—É—Ö–æ—Ü–≤–µ—Ç', '–∫–∞–º–Ω']):
            metadata['post_type'] = 'decor'
        elif any(word in post_lower for word in ['–∑–∞–∫–∞–∑', '–ø–æ–¥–∞—Ä–æ–∫', '—Ü–µ–Ω–∞']):
            metadata['post_type'] = 'commercial'
        elif any(word in post_lower for word in ['–ø—Ä–æ—Ü–µ—Å—Å', '—Å–æ–∑–¥–∞–Ω', '–∏–∑–≥–æ—Ç–æ–≤–ª']):
            metadata['post_type'] = 'process'
        
        topics = []
        topic_keywords = {
            '–∞—Ä–æ–º–∞—Ç—ã': ['–∞—Ä–æ–º–∞—Ç', '–∑–∞–ø–∞—Ö', '–ø–∞—Ä—Ñ—é–º', '–æ—Ç–¥—É—à–∫'],
            '–¥–µ–∫–æ—Ä': ['–¥–µ–∫–æ—Ä', '—Å—É—Ö–æ—Ü–≤–µ—Ç', '–∫–∞–º–Ω', '—É–∫—Ä–∞—à–µ–Ω'],
            '–ø—Ä–æ—Ü–µ—Å—Å': ['–ø—Ä–æ—Ü–µ—Å—Å', '—Å–æ–∑–¥–∞–Ω', '–∏–∑–≥–æ—Ç–æ–≤–ª', '—Ä—É—á–Ω'],
            '–º–∞—Ç–µ—Ä–∏–∞–ª—ã': ['–≤–æ—Å–∫', '–∫–æ–∫–æ—Å–æ–≤', '–Ω–∞—Ç—É—Ä–∞–ª—å–Ω', '–∫–∞—á–µ—Å—Ç–≤'],
            '–ø—Ä–∞–∑–¥–Ω–∏–∫–∏': ['–Ω–æ–≤–æ–≥–æ–¥', '—Ä–æ–∂–¥–µ—Å—Ç–≤', '8 –º–∞—Ä—Ç–∞', '–ø—Ä–∞–∑–¥–Ω–∏–∫'],
            '–ø–æ–¥–∞—Ä–∫–∏': ['–ø–æ–¥–∞—Ä–æ–∫', '–ø–æ–¥–∞—Ä', '–∑–∞–∫–∞–∑', '—Å—é—Ä–ø—Ä–∏–∑']
        }
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in post_lower for keyword in keywords):
                topics.append(topic)
        
        metadata['topics'] = topics
        
        if any(word in post_lower for word in ['–Ω–æ–≤–æ–≥–æ–¥', '—Ä–æ–∂–¥–µ—Å—Ç–≤', '–∑–∏–º']):
            metadata['season'] = 'winter'
        elif any(word in post_lower for word in ['–≤–µ—Å–Ω', '8 –º–∞—Ä—Ç–∞']):
            metadata['season'] = 'spring'
        elif any(word in post_lower for word in ['–ª–µ—Ç']):
            metadata['season'] = 'summer'
        elif any(word in post_lower for word in ['–æ—Å–µ–Ω']):
            metadata['season'] = 'autumn'
        
        return metadata
    
    def _create_embeddings(self):
        logger.info("Creating embeddings for posts...")
        self.embeddings = self.encoder.encode(self.posts, show_progress_bar=True)
        logger.info("Embeddings created successfully")
    
    def _retrieve_similar_posts(self, query: str, num_posts: int = 5, 
                              post_type_filter: Optional[str] = None) -> List[RetrievedPost]:
        query_embedding = self.encoder.encode([query])
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        sorted_indices = np.argsort(similarities)[::-1]
        
        retrieved_posts = []
        for idx in sorted_indices:
            if len(retrieved_posts) >= num_posts:
                break
                
            if post_type_filter and self.post_metadata[idx]['post_type'] != post_type_filter:
                continue
            
            retrieved_post = RetrievedPost(
                content=self.posts[idx],
                similarity=similarities[idx],
                post_type=self.post_metadata[idx]['post_type'],
                keywords=self.post_metadata[idx]['topics']
            )
            retrieved_posts.append(retrieved_post)
        
        return retrieved_posts
    
    def _create_system_prompt(self, task_type: str) -> str:
        base_persona = """–¢—ã - –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å–Ω–∏—Ü–∞ –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞ —Å–≤–µ—á–µ–π —Ä—É—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã. –¢—ã —Å–æ–∑–¥–∞—ë—à—å —Ä–æ—Å–∫–æ—à–Ω—ã–µ —Å–≤–µ—á–∏ —Å –∞—Ä–æ–º–∞—Ç–∞–º–∏ –∫—É–ª—å—Ç–æ–≤—ã—Ö –ø–∞—Ä—Ñ—é–º–æ–≤.

–¢–í–û–Ø –õ–ò–ß–ù–û–°–¢–¨:
- –≠–ª–µ–≥–∞–Ω—Ç–Ω–∞—è, —Ç—ë–ø–ª–∞—è –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤–æ–≤–ª–µ–∫–∞—é—â–∞—è
- –°—Ç—Ä–∞—Å—Ç–Ω–æ —É–≤–ª–µ—á–µ–Ω–∞ —Å–≤–æ–∏–º –¥–µ–ª–æ–º
- –ò—Å–ø–æ–ª—å–∑—É–µ—à—å —ç–º–æ–¥–∑–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏ (üíã, üïØ, ‚ú®, ü•∞, üå∫)
- –ü–∏—à–µ—à—å —Å –¥—É—à–æ–π –∏ –¥–ª—è –¥—É—à–∏

–ë–†–ï–ù–î:
- –†–æ—Å–∫–æ—à–Ω—ã–µ —Å–≤–µ—á–∏ —Ä—É—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ –∫–æ–∫–æ—Å–æ–≤–æ–º –≤–æ—Å–∫–µ
- –≠–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ –ø–∞—Ä—Ñ—é–º–µ—Ä–Ω—ã–µ –æ—Ç–¥—É—à–∫–∏ –∏–∑ –ï–≤—Ä–æ–ø—ã
- –ù–∞—Ç—É—Ä–∞–ª—å–Ω—ã–π –¥–µ–∫–æ—Ä (—Å—É—Ö–æ—Ü–≤–µ—Ç—ã, –¥—Ä–∞–≥–æ—Ü–µ–Ω–Ω—ã–µ –∫–∞–º–Ω–∏)
- –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–∞–∂–¥–æ–º—É –∑–∞–∫–∞–∑—É
- –í—Ä–µ–º—è –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è: 4-6 –¥–Ω–µ–π
- –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞—ë—à—å –∏–∑—ã—Å–∫–∞–Ω–Ω—ã–µ –∞—Ä–æ–º–∞–¥–∏—Ñ—Ñ—É–∑–æ—Ä—ã

–°–¢–ò–õ–¨ –ü–ò–°–¨–ú–ê:
- –ù–∞—á–∏–Ω–∞–µ—à—å —Å —ç–º–æ–¥–∑–∏ –∏–ª–∏ —Ü–µ–ø–ª—è—é—â–µ–≥–æ –∫—Ä—é—á–∫–∞
- –ò—Å–ø–æ–ª—å–∑—É–µ—à—å –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫
- –í–∫–ª—é—á–∞–µ—à—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ö–µ—à—Ç–µ–≥–∏
- –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—à—å —Ç–µ–ø–ª–æ, —á–∞—Å—Ç–æ —Ñ–∏—Ä–º–µ–Ω–Ω—ã–º–∏ —Ñ—Ä–∞–∑–∞–º–∏
- –°–æ—á–µ—Ç–∞–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ —Å lifestyle-–∫–æ–Ω—Ç–µ–Ω—Ç–æ–º"""

        if task_type == "post_writing":
            return base_persona + """

–ó–ê–î–ê–ß–ê: –ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è —Ç–æ–Ω–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –º–∞–Ω–µ—Ä—ã –∏–∑–ª–æ–∂–µ–Ω–∏—è. –°–æ—Ö—Ä–∞–Ω—è–π –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –∏ —Å—Ç—Ä–∞—Å—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–∏—é –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã—Ö –∞—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–π."""

        elif task_type == "idea_generation":
            return base_persona + """

–ó–ê–î–ê–ß–ê: –ì–µ–Ω–µ—Ä–∏—Ä—É–π –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –∏–¥–µ–∏ –¥–ª—è –ø–æ—Å—Ç–æ–≤, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤. –ü—Ä–µ–¥–ª–∞–≥–∞–π —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã: –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ, —Å–µ–∑–æ–Ω–Ω—ã–µ, –ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ, –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ."""

        elif task_type == "research":
            return base_persona + """

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–≤–æ–¥–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –æ —Å–≤–µ—á–∞—Ö, –∞—Ä–æ–º–∞—Ç–∞—Ö, —Ç—Ä–∞–¥–∏—Ü–∏—è—Ö –∏ –≤—Å—ë–º, —á—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –º–∏—Ä–æ–º —Å–≤–µ—á–µ–π. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ –æ—Å–Ω–æ–≤—É –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –∏ —Å—Ç–∏–ª—è –ø–æ–¥–∞—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."""

        elif task_type == "conversation":
            return base_persona + """

–ó–ê–î–ê–ß–ê: –í–µ–¥–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é –±–µ—Å–µ–¥—É. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏ —Ä–µ–∞–≥–∏—Ä—É–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ:

1. **–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏–∑–º–µ–Ω–∏—Ç—å/—É–ª—É—á—à–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç** - –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –Ω–∞–π–¥–∏ —á—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å, –∏ –≤–Ω–µ—Å–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–µ –ø—Ä–∞–≤–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–≤–æ–π —Å—Ç–∏–ª—å.

2. **–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–µ—Ç –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –º–µ–Ω—è–µ—Ç —Ç–µ–º—É** - –æ—Ç–≤–µ—á–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ —Ç–µ–ø–ª–æ. –ú–æ–∂–µ—à—å –¥–µ–ª–∏—Ç—å—Å—è –ª–∏—á–Ω—ã–º–∏ –º—ã—Å–ª—è–º–∏, –æ–ø—ã—Ç–æ–º, —Å–æ–≤–µ—Ç–∞–º–∏.

3. **–ï—Å–ª–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä –∫–∞—Å–∞–µ—Ç—Å—è —Å–≤–µ—á–µ–π, –∞—Ä–æ–º–∞—Ç–æ–≤ –∏–ª–∏ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞** - —Å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–π –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –Ω–æ –Ω–µ –ø—Ä–µ–≤—Ä–∞—â–∞–π –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –≤ —Ä–µ–∫–ª–∞–º—É.

–ë—É–¥—å –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ–π –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≤ –æ–±—â–µ–Ω–∏–∏. –ï—Å–ª–∏ –Ω–µ—è—Å–Ω–æ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –æ—Ç–≤–µ—Ç–µ, –≤–µ–∂–ª–∏–≤–æ —É—Ç–æ—á–Ω–∏."""

        elif task_type == "refinement":
            return base_persona + """

–ó–ê–î–ê–ß–ê: –¢—ã –ø–æ–ª—É—á–∞–µ—à—å –∑–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ —Ä–∞–Ω–µ–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –Ω–∞–π–¥–∏ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å, –∏ –≤–Ω–µ—Å–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–µ –ø—Ä–∞–≤–∫–∏. –°–æ—Ö—Ä–∞–Ω—è–π —Å–≤–æ–π —Å—Ç–∏–ª—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ. –í–æ–∑–º–æ–∂–Ω—ã–µ —Ç–∏–ø—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π:
- –°–¥–µ–ª–∞—Ç—å –∫–æ—Ä–æ—á–µ/–¥–ª–∏–Ω–Ω–µ–µ
- –ò–∑–º–µ–Ω–∏—Ç—å —Ç–æ–Ω (—Ñ–æ—Ä–º–∞–ª—å–Ω–µ–µ/–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–µ–µ)
- –î–æ–±–∞–≤–∏—Ç—å/—É–±—Ä–∞—Ç—å –¥–µ—Ç–∞–ª–∏
- –ü–µ—Ä–µ–ø–∏—Å–∞—Ç—å –≤ –¥—Ä—É–≥–æ–º —Å—Ç–∏–ª–µ
- –ò—Å–ø—Ä–∞–≤–∏—Ç—å –∏–ª–∏ —É–ª—É—á—à–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω, –≤–µ–∂–ª–∏–≤–æ —É—Ç–æ—á–Ω–∏ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å."""

        return base_persona

    def generate_post(self, user_request: str, style_examples: int = 4, conversation_context: str = "") -> str:
        logger.info(f"Generating post for request: {user_request[:50]}...")
        
        similar_posts = self._retrieve_similar_posts(user_request, style_examples)
        
        examples_text = "\n\n--- –ü–†–ò–ú–ï–†–´ –¢–í–û–ò–• –ü–û–°–¢–û–í ---\n"
        for i, post in enumerate(similar_posts, 1):
            examples_text += f"\n–ü—Ä–∏–º–µ—Ä {i} (—Å—Ö–æ–∂–µ—Å—Ç—å: {post.similarity:.2f}):\n{post.content}\n"
        
        system_prompt = self._create_system_prompt("post_writing")
        context_text = conversation_context if conversation_context else ""
        user_prompt = f"{context_text}{examples_text}\n\n--- –ó–ê–î–ê–ù–ò–ï ---\n–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –Ω–∞ —Ç–µ–º—É: {user_request}\n\n–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã –≤—ã—à–µ –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å —Ç–≤–æ–µ–≥–æ —Å—Ç–∏–ª—è, —Ç–æ–Ω–∞ –∏ –º–∞–Ω–µ—Ä—ã –∏–∑–ª–æ–∂–µ–Ω–∏—è. –ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.8,
            max_tokens=1000
        )
        
        return response.choices[0].message.content
    
    def generate_post_ideas(self, theme: str = "", num_ideas: int = 5, conversation_context: str = "") -> str:
        logger.info(f"Generating {num_ideas} post ideas for theme: {theme}")
        
        if theme:
            similar_posts = self._retrieve_similar_posts(theme, 6)
        else:
            similar_posts = []
            post_types = ['educational', 'seasonal', 'fragrance', 'decor', 'commercial']
            for post_type in post_types:
                posts = self._retrieve_similar_posts("—Å–≤–µ—á–∏", 2, post_type)
                similar_posts.extend(posts)
        
        examples_text = "\n\n--- –£–°–ü–ï–®–ù–´–ï –ü–û–°–¢–´ –î–õ–Ø –í–î–û–•–ù–û–í–ï–ù–ò–Ø ---\n"
        for i, post in enumerate(similar_posts, 1):
            examples_text += f"\n–ü–æ—Å—Ç {i} ({post.post_type}):\n{post.content}\n"
        
        system_prompt = self._create_system_prompt("idea_generation")
        context_text = conversation_context if conversation_context else ""
        theme_text = f" –Ω–∞ —Ç–µ–º—É '{theme}'" if theme else ""
        user_prompt = f"{context_text}{examples_text}\n\n--- –ó–ê–î–ê–ù–ò–ï ---\n–ü—Ä–µ–¥–ª–æ–∂–∏ {num_ideas} –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã—Ö –∏–¥–µ–π –¥–ª—è –ø–æ—Å—Ç–æ–≤{theme_text}.\n\n–û—Å–Ω–æ–≤—ã–≤–∞–π—Å—è –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤—ã—à–µ. –ö–∞–∂–¥–∞—è –∏–¥–µ—è –¥–æ–ª–∂–Ω–∞ –≤–∫–ª—é—á–∞—Ç—å:\n- –ó–∞–≥–æ–ª–æ–≤–æ–∫/—Ç–µ–º—É\n- –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è\n- –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —Å—Ç–∏–ª—å –ø–æ–¥–∞—á–∏\n- –í–æ–∑–º–æ–∂–Ω—ã–µ —ç–º–æ–¥–∑–∏ –∏ —Ö–µ—à—Ç–µ–≥–∏"
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.9,
            max_tokens=1200
        )
        
        return response.choices[0].message.content
    
    def research_topic(self, research_query: str, conversation_context: str = "") -> str:
        logger.info(f"Researching topic: {research_query}")
        
        relevant_posts = self._retrieve_similar_posts(research_query, 4)
        
        context_text = "\n\n--- –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –¢–í–û–ò–• –ü–û–°–¢–û–í ---\n"
        for i, post in enumerate(relevant_posts, 1):
            context_text += f"\n–ü–æ—Å—Ç {i}:\n{post.content}\n"
        
        system_prompt = self._create_system_prompt("research")
        conversation_text = conversation_context if conversation_context else ""
        user_prompt = f"{conversation_text}{context_text}\n\n--- –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï ---\n–ò—Å—Å–ª–µ–¥—É–π —Ç–µ–º—É: {research_query}\n\n–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ –∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ—Å—Ç–∞. –í–∫–ª—é—á–∏:\n- –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ñ–∞–∫—Ç—ã\n- –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã\n- –°–≤—è–∑—å —Å –∞—Ä–æ–º–∞—Ç–µ—Ä–∞–ø–∏–µ–π/—Å–≤–µ—á–∞–º–∏\n- –ò–¥–µ–∏ –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–π –ø–æ–¥–∞—á–∏\n\n–û—Å–Ω—É–π—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏–∑ –º–æ–∏—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ—Å—Ç–æ–≤ –∏ –¥–æ–ø–æ–ª–Ω–∏ –Ω–æ–≤–æ–π –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    def refine_content(self, refinement_request: str, conversation_context: str, content_type: str = "general") -> str:
        logger.info(f"Refining {content_type} content: {refinement_request[:50]}...")
        
        system_prompt = self._create_system_prompt("refinement")
        user_prompt = f"{conversation_context}\n\n--- –ó–ê–ü–†–û–° –ù–ê –ò–ó–ú–ï–ù–ï–ù–ò–ï ---\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç: {refinement_request}\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä –∏ –Ω–∞–π–¥–∏ –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å. –í–Ω–µ—Å–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è—è –º–æ–π —Å—Ç–∏–ª—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –ø–æ—Å—Ç, –∏–¥–µ–∏ –∏–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ - —Å–¥–µ–ª–∞–π —ç—Ç–æ. –ï—Å–ª–∏ –ø—Ä–æ—Å—å–±–∞ –Ω–µ—è—Å–Ω–∞, —É—Ç–æ—á–Ω–∏ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.8,
            max_tokens=1200
        )
        
        return response.choices[0].message.content
    
    def conversational_chat(self, user_message: str, conversation_context: str = "") -> str:
        logger.info(f"Processing conversational message: {user_message[:50]}...")
        
        system_prompt = self._create_system_prompt("conversation")
        user_prompt = f"{conversation_context}\n\n--- –¢–ï–ö–£–©–ï–ï –°–û–û–ë–©–ï–ù–ò–ï ---\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏–∑–º–µ–Ω–∏—Ç—å –∏–ª–∏ —É–ª—É—á—à–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç - —Å–¥–µ–ª–∞–π —ç—Ç–æ. –ï—Å–ª–∏ —ç—Ç–æ –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Ç–µ–º–∞ - –æ—Ç–≤–µ—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.9,
            max_tokens=800
        )
        
        return response.choices[0].message.content
    
    def interactive_session(self):
        print("üïØ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ RAG Bot! üïØ")
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
        print("1. '–ø–æ—Å—Ç: [–æ–ø–∏—Å–∞–Ω–∏–µ]' - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞")
        print("2. '–∏–¥–µ–∏: [—Ç–µ–º–∞]' - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–¥–µ–π –¥–ª—è –ø–æ—Å—Ç–æ–≤")
        print("3. '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: [—Ç–µ–º–∞]' - –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ç–µ–º—ã")
        print("4. '–≤—ã—Ö–æ–¥' - –∑–∞–≤–µ—Ä—à–∏—Ç—å —Å–µ—Å—Å–∏—é")
        print("-" * 50)
        
        while True:
            try:
                user_input = input("\nüí´ –í–∞—à –∑–∞–ø—Ä–æ—Å: ").strip()
                
                if user_input.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
                    print("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! üíã")
                    break
                
                if user_input.startswith('–ø–æ—Å—Ç:'):
                    request = user_input[5:].strip()
                    if request:
                        result = self.generate_post(request)
                        print(f"\nüìù –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç:\n{result}")
                    else:
                        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É –ø–æ—Å—Ç–∞ –ø–æ—Å–ª–µ '–ø–æ—Å—Ç:'")
                
                elif user_input.startswith('–∏–¥–µ–∏:'):
                    theme = user_input[5:].strip()
                    result = self.generate_post_ideas(theme)
                    print(f"\nüí° –ò–¥–µ–∏ –¥–ª—è –ø–æ—Å—Ç–æ–≤:\n{result}")
                
                elif user_input.startswith('–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ:'):
                    topic = user_input[12:].strip()
                    if topic:
                        result = self.research_topic(topic)
                        print(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:\n{result}")
                    else:
                        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ:'")
                
                else:
                    print("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ '–ø–æ—Å—Ç:', '–∏–¥–µ–∏:', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ:' –∏–ª–∏ '–≤—ã—Ö–æ–¥'")
                    
            except KeyboardInterrupt:
                print("\n\n–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! üíã")
                break
            except Exception as e:
                logger.error(f"Error in interactive session: {e}")
                print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

def main():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("OPENAI_API_KEY environment variable is not set.")
        api_key = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenAI API –∫–ª—é—á: ").strip()
        if not api_key:
            print("API –∫–ª—é—á –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env")
            return
    
    try:
        rag_bot = AromaKissRAG(api_key)
        rag_bot.interactive_session()
        
    except Exception as e:
        logger.error(f"Failed to initialize RAG bot: {e}")
        print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

if __name__ == "__main__":
    main() 